\documentclass{article}
\usepackage{graphicx}
\usepackage{algorithm}
\usepackage[noend]{algorithmic}
\usepackage{subfigure}
\usepackage{amssymb, amsmath, graphicx, charter, latexsym}
\usepackage{layouts}
\usepackage[letterpaper]{geometry}
\usepackage{enumerate}
\usepackage{epstopdf}
\usepackage{ragged2e}
%\usepackage{times}
\usepackage{mathtools}
%\usepackage[scaled]{helvet}
\usepackage{mathptmx}
\usepackage{verbatim}
\usepackage{listings}
\usepackage{siunitx}
\usepackage{booktabs}
\usepackage{array}
\DeclareMathOperator*{\argmin}{arg\,min}
\DeclareMathOperator*{\argmax}{arg\,max}
\newcolumntype{P}[1]{>{\centering\arraybackslash}p{#1}}

\lstset{
basicstyle=\ttfamily,
}
\lstMakeShortInline|

\begin{document}

\title{\bfseries ECEN 689 -- Real-Time Wireless Networks: Project 3\\
Smart Scheduling with Point Coordination Function\\
 for WiFi Uplink Transmissions}
\date{Due on 5/6}
\author{%
Ping-Chun Hsieh\\
\texttt{lleyfede@tamu.edu}
\and
Tao Zhao\\
\texttt{alick@tamu.edu}
\and
Dongni Han\\
\texttt{handongni2015@tamu.edu}
}
\maketitle

\section*{Terminology}

In our report, we use AP or ``server'' to denote the WiFi access point, and ``client'' to denote the terminal device such as a mobile phone, a tablet, and so on. Throughout our simulation, we let node $0$ be the server, and the other nodes be the clients. The basic time unit for packet transmission is called \emph{slot}, which should be greater than a round-trip time (RTT). For real-time traffic, we group an integer number (denoted by $T$) of slots into an \emph{interval}, which is the relative deadline of the packets.

\section{Background}
\subsection{System Model}
We consider a wireless network of one AP and $N$ clients, where $N\ge1$. We consider uplink transmission with point coordination function (PCF) with real-time traffic. For uplink transmission, packets are generated by each client $n$ in the beginning of each interval. In each interval, the number of packets generated by client $n$, denoted by $X_n$, follows a uniform distribution in the range of [$U_{min}$, $U_{max}$]. In PCF mode, AP polls at most one client per slot and it has full control over channel allocation. In the beginning of each interval, each client generates a random number of packets and waits for channel access that is fully controlled by the AP. Since the packets are generated and queued on the client's side, the AP needs to collect the queue information of the clients to make scheduling decisions.

\subsection{Baseline Policy}
Under the baseline policy, the AP first collects the queue information by polling each client one by one for the number of data packets it generates ($X_n$). After all clients are polled, the AP knows the number of packets at each client. Next, the AP uses the Max-Weight policy to schedule one of the clients in each time slot for actual data transmission. 

The major issue in the baseline policy is that there is no data transmission in the polling phase. As a result, channel utilization for data packets can be very low. Moreover, the channel utilization is especially low with large network size or poor wireless channels since the AP ends up spending most of the time on polling queue information.

\section{Smart Policy}

We introduce three different features to improve network performance with real-time traffic.
\subsection{Selective Polling}
The first feature is selective polling. In each interval, the AP only polls the queue information of a subset of $n \le N $ clients. By properly choosing $n$, the AP avoids spending too much time on polling queue information while collecting enough queue information for scheduling. The process of determining the optimal $n$ includes the following three steps:
\begin{enumerate}
\item Sort clients by channel reliabilities $p_1 \geq p_2 \geq \dots \geq p_N$
\item Estimated throughput: $\hat{R}_n = \min\{n\frac{U_{min}+U_{max}}{2}, (T-\sum_{i=1}^{n}\frac{1}{p_i})\frac{\sum_{i=1}^{n}p_i}{n} \}$
\item Find the optimum $n^* = \argmax_{n} \hat{R}_n$
\end{enumerate}
Step 1 allows us to look at only the first $n$ clients in step 2. In step 2, $(T-\sum_{i=1}^{n}\frac{1}{p_i})$ serves as an estimate of the average number of slots available for data packets and $(\frac{\sum_{i=1}^{n}p_i}{n})$ is the average channel reliability of this subset of clients.
In selecting clients, we apply random permutation for better fairness by using Knuth shuffle algorithm. When all of the selected clients are served completely, we consider the  remaining clients by serving them one by one.
[NEED TO ADD MORE IMPLEMENTATION DETAILS]

\subsection{Piggybacked Queue Length}

The polling overhead can be greatly mitigated by allowing piggybacked queue information. When a client receives a polling message, it replies with its queue length $X_n$ as well as the first data message (if there is any) in one packet to the AP. Hence, all slots become effectively available for data transmission. Consequently, when this feature is combined with selective polling, the estimated throughput used in selective polling should be modified as $\hat{R}_n = \min \{n\frac{U_{min}+U_{max}}{2}, T \frac{\sum_{i=1}^{n}p_i}{n} \}$. 

To implement this feature in ns-2, we introduce two new packet types: \lstinline|SWiFi_PKT_POLL_PGBK| for the AP and \lstinline|SWiFi_PKT_PGBK_UL| for the clients. The queue information is maintained in the header of \lstinline|SWiFi_PKT_PGBK_UL| packets. This feature is designed to be enabled/disabled by one boolean variable.

\subsection{Retry Limit for Polling}

Consider a network where there is one client with zero channel reliability. Under the baseline policy, the AP will keep polling the queue information of that unconnected client indefinitely and end up producing zero data throughput. As a countermeasrue, retry limit for polling can prevent the AP from spending too much time on polling clients with poor channels. 
To implement this feature, we choose to disable the built-in retry function of 802.11 MAC and handle retransmission completely in the application layer. This allows us to have full control over the timing of retransmissions. We introduce a variable \lstinline|num_retry_| to keep track of the number of retries. When the AP starts polling a new client, \lstinline|num_retry_| is set to 0. \lstinline|num_retry_| increases by 1 after each polling retry. If the retry limit is reached, the AP then starts polling the next client regardless of the result of the last transmission. 

\subsection{Smart Policy}
Our smart policy combines selective polling, piggybacked queue length, and retry limit for polling to handle the polling issue in the baseline policy. For better modularity, our design allows users to enable the above three features independently. In Tcl domain, we use binary digits to represent different types of policies. All combinations of the three features are shown in Table \ref{Policy Types}. 

\begin{table}[htbp]
   \centering
   \caption{Policy types and binary representation.}
   \label{Policy Types}
   \begin{tabular}{| P{4cm} | P{3.5cm} |}
       \hline
       Policy Types   &  Binary representation\\   \hline
       Baseline &  000\\ \hline
       Selective & 001\\ \hline
       Piggyback & 010\\ \hline
       Selective + Piggyback & 011\\ \hline
       Retry Limit  &100\\ \hline
       Selective+ Retry Limit & 101\\ \hline
       Piggyback + Retry Limit & 110\\ \hline
       Smart &  111\\
       \hline
   \end{tabular}
\end{table} 

%\begin{enumerate}
%\item Select a subset of clients to poll $X_n$.
%\item AP polls clients in expect of piggybacking reply.
%\item AP repeats polling a client for limited times.
%\end{enumerate}

%\section{Implementation in NS-2}
%\label{section: ns2}

\section{Simulation Results}
\label{section: simulation}

\end{document}